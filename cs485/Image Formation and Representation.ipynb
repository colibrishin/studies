{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Based on https://www.cse.unr.edu/~bebis/CS485/*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Formation and Representation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple model of image formation\n",
    "    Scene is...\n",
    "        Illuminated by a single source\n",
    "        Reflects radiation towards the camera\n",
    "        Senses it via Solid State Cells (CCD Cameras)\n",
    "$$\n",
    "    f(x,y)=i(x,y)r(x,y) \\\\\n",
    "    \\text{where i : illumination, r : reflectance}\n",
    "$$\n",
    "![title](img/simple_model_of_image_formation.jpg)\n",
    "- Geometry\n",
    "    - Determines where in the image plane the projection of a point in the scene will be located\n",
    "- Physics of Light\n",
    "    - Determines the brightness of a point in the image plane"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's design a camera\n",
    "### \"A Barrier\"\n",
    "![title](img/pinhole_camera.png)\n",
    "- Add a barrier with a small opening (i.e. **aperture**) to block off most of the rays to reduce blurring\n",
    "- \"Pinhole\" camera model\n",
    "    - Rays of light pass through a \"pinhole\" and form an **inverted** image of the object on the image plane.\n",
    "- Perspective projection\n",
    "$$\n",
    "    x = fX/Z \\\\\n",
    "    y = fY/Z \\\\\n",
    "    \\text{where f: focal length}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Effect of aperture size\n",
    "![title](img/aperture1.jpg)\n",
    "![title](img/aperture2.jpg)\n",
    "- Small\n",
    "    - Reduce blurring\n",
    "    - Limit the amount of light entering the camrea\n",
    "    - Light Diffraction (Light scattered, FOV distortion)\n",
    "- Large\n",
    "    - Light from the source spreads across the image (i.e, not properly focused)\n",
    "    - Blurry"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lens\n",
    "    Lens duplicate pinhole geometry without resorting to undesirably small apertures.\n",
    "        - Gather all the light radiating from an object point towards the lens' finite aperture\n",
    "        - Bring light into focus at single distinct image point\n",
    "![title](img/lens.png)\n",
    "![title](img/lens_to_image.jpg)\n",
    "- Refraction\n",
    "    - Bending of wave when it enters a medium where its speed is different\n",
    "\n",
    "![title](img/lens_goes_light.png)\n",
    "- Focal point\n",
    "    - Rays are perpendicular to the lens\n",
    "### Properties of \"thin\" lens\n",
    "- Focal plane \n",
    "    - The plane parallel to the lens at the focal point\n",
    "- Focal length $f$\n",
    "    - The distance between the lens and the focal plane"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Equation\n",
    "$$\n",
    "\\text{Assume an object at distance } u \\text{ from the lens plane:} \\\\\n",
    "$$\n",
    "![title](img/equation1.png)\n",
    "$$\n",
    "\\text{Using similar triangles:}\\\\\n",
    "y'/y = v/u\n",
    "$$\n",
    "![title](img/equation2.png)\n",
    "$$\n",
    "y'/y = (v-f)/f\n",
    "$$\n",
    "![title](img/equation3.png)\n",
    "$$\n",
    "1/u + 1/v = 1/f\n",
    "$$\n",
    "![title](img/equation4.png)\n",
    "- The thin lens equation implies that only points at distance u from the lens are \"in focus\" \n",
    "    - (i.e, focal point lies on image plane)\n",
    "- Other points project to a \"blur circle\" or \"circle of confusion\" in the image \n",
    "    - (i.e, blurring occurs)\n",
    "- When objects move far away from the camera, then the focal plane approaches the image plane."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Depth of Field\n",
    "    The range of depths over which the world is approximately sharp (i.e, in focus)\n",
    "- The size of blur circle is proportional to aperture size\n",
    "- Changing aperture size (controlled by diaphragm) affects depth of field\n",
    "    - A smaller aperture = increases the range + need to increase exposure time\n",
    "    - A larger apertrue = decreases the depth of field + need to decrease exposure time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Field of View\n",
    "    The cone of viewing direction of the camera. Inversely proportional to focal length.\n",
    "![title](img/fov1.png)\n",
    "![title](img/fov2.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example. Car\n",
    "- Small $f$, Large FOV \\\n",
    "    ![title](img/small_f_car.png)\n",
    "- Large $f$, Small FOV \\\n",
    "    ![title](img/large_f_car.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example. Face \n",
    "(small $f$ to large $f$, large FOV to small FOV)\\\n",
    "![title](img/face_distort1.jpg) \\\n",
    "![title](img/face_distort2.jpg) \\\n",
    "![title](img/face_distort3.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Real lenses\n",
    "![title](img/real_lenses.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lens Flaws\n",
    "#### Chromatic Aberration\n",
    "    Lens has different refractive indices for different wavelengths\n",
    "    Could cause color fringing\n",
    "        i.e lens cannot focus all the colors at the same point.\n",
    "![title](img/chromatic_aberration1.jpg)\n",
    "![title](img/chromatic_aberration2.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Radial Distortion\n",
    "    Straight lines become distorted as we move further away from the center of the image\n",
    "    Deviations are most noticeable for rays that pass through the edge of the lens\n",
    "![title](img/radial_distortion1.jpg)\n",
    "![title](img/radial_distortion2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tangential Distortion\n",
    "    Lens is not exactly parallel to the imaging plane"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Human Eye\n",
    "    aperture (= pupil), lens mechanism for focusing(zoom in/out), surface for registering images (= retina)\n",
    "![title](img/human_eye.png)\n",
    "- In a camera, focusing at various distances is achieved by varying the distance between the lens and the imaging plane\n",
    "- In the human eye, the distance between the lens and the retina is fixed (14 ~ 17 mm)\n",
    "- Focusing is achieved by varying the shape of the lens (= flattening of thickening by using ciliary muscle, fiber-?)\n",
    "- Retina contains light sensitive cells that convert light energy into electrical impusles that travel through nerves to the brain\n",
    "- Brain interprets the electrical signals to form images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Two kinds of light-sensitive cells\n",
    "    - 간상세포 rods and 원뿔세포 cone (unevenly distributed)\n",
    "    - Cones (6-7 million)\n",
    "        - Responsible for all color vision and are present throughout the retina\n",
    "        - but are concentrated toward the center of the field of vision at the back of the retina\n",
    "        - Short Cone corresponds to blue, Medium corresponds to green, Long corresponds to red\n",
    "        - Ratio of L to M to S = 10:5:1\n",
    "    - Rods (120 million)\n",
    "        - More sensitive to light than cones but cannot discern color. (명암)\n",
    "        - Primary receptors for night vision and detecting motion.\n",
    "        - Large amount of light overwhelms them, and they take a long time to \"reset\" and adapt to the dark again.\n",
    "        - Once fully adadpted to darkness, the rods are 10,000 times more sensitive to light than the cones.\n",
    "    - Fovea (Speical Area)\n",
    "        - Mostly cones\n",
    "        - Almost no S cones in the center of the fovea\n",
    "        - color sensitivity and resolution are highest."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Digital cameras\n",
    "    Digital camera replaces film with a sensor array.\n",
    "    Each cell in the array is light-sensitive diode that converts photons to electrons.\n",
    "- Two common types\n",
    "    - Charged Coupled Device (CCD)\n",
    "        - CCDs move photogenerated charge from pixel to pixel and convert it to voltage at an output node.\n",
    "        - An analog-to-digital converter(ADC) then turns each pixel's value into a digital value.\n",
    "    - Complementary Metal Oxide Semiconductor (CMOS)\n",
    "        - CMOS convert charge to voltage inside each element.\n",
    "        - Uses several transistors at teach pixel to amplify and move the charge using more traditional wires.\n",
    "        - The CMOS signal is digital, so it needs no ADC.\n",
    "\n",
    "![title](img/ccd.jpg)\n",
    "### Color sensing in camera: Prism\n",
    "- Requires three chips and precise alignment\n",
    "- out of 2 cones, L/M cones cover green, human can recognize green easily.\n",
    "\n",
    "![title](img/prism1.png)\n",
    "![title](img/prism2.png)\n",
    "\n",
    "### Color sensing in camera: Color filter array\n",
    "- In traditional systems, color filters are applied to a single layer of photodetectors in a tiled mosaic patter.\n",
    "\n",
    "![title](img/color_filter_array1.jpg)\n",
    "![title](img/color_filter_array2.png)\n",
    "\n",
    "### Color sensing in camera: Foveon X3\n",
    "- CMOS sensor; takes advantage of the fact that red, blue and green light silicon to different depts.\n",
    "\n",
    "![title](img/foveonx3.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image Digitization\n",
    "- Sampling\n",
    "    - Measure the value of an image at a finite number of points.\n",
    "- Quantization\n",
    "    - Represent measured value (i.e, voltage) at the sampled point by an integer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alternative Color Spaces\n",
    "- Decorrelating the color channels\n",
    "    - Principal Components\n",
    "- Bringing color information to the fore:\n",
    "    - HSV\n",
    "- Perceptual uniformity\n",
    "    - CIELuv, CIELab, ...."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Color Transformation Example\n",
    "![title](img/HSV.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Skin Color\n",
    "![title](img/skin_color.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image File Format\n",
    "    The header contains at least the width and height of the image\n",
    "    Most header being with a signature or magic number\n",
    "![title](img/file_header.jpg)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
